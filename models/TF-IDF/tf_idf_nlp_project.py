# -*- coding: utf-8 -*-
"""TF-IDF_NLP_Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EmlO_DMjz5hdgEQdEf33YitP1g1Ps_Hw
"""



import pickle


with open('/content/drive/My Drive/NLP_Project/corpus_dict_5000.pkl', 'rb') as f:
    data = pickle.load(f)

first = next(iter(data.values()))

corpus = []
for i in iter(data.values()):
  for j in i:
    k = ''.join([u for u in j if not u.isdigit()])
    corpus.append(k)

corpus[:10]

from pandas import DataFrame
df = DataFrame (corpus,columns=['headline_text'])
df_text = df[['headline_text']]
df_text['index'] = df_text.index
documents = df_text

documents

import gensim
from gensim.utils import simple_preprocess
from gensim.parsing.preprocessing import STOPWORDS
from nltk.stem import WordNetLemmatizer, SnowballStemmer
from nltk.stem.porter import *
import numpy as np
np.random.seed(2018)
import pandas as pd
stemmer = SnowballStemmer('english')

import nltk
nltk.download('wordnet')

from sklearn.feature_extraction.text import TfidfVectorizer

# Create TfidfVectorizer object
vectorizer = TfidfVectorizer()

# Generate matrix of word vectors
tfidf_matrix = vectorizer.fit_transform(corpus)

# Print the shape of tfidf_matrix
print(tfidf_matrix.shape)



test_corpus = ["The recommendation problem can be defined as estimating the response of a user for new items, based on historical information stored in the system, \
              and suggesting to this user novel and original items for which the predicted response is high. User item responses can be numerical values known as ratings (e.g., 1–5 stars),\
              ordinal values (e.g., strongly agree, agree, neutral, disagree, strongly disagree) representing the possible levels of user appreciation, or binary values \
              (e.g., like/dislike or interested/not interested). Moreover, user responses can be obtained explicitly, forinstance, through ratings/reviews entered by users in the system, or implicitly, from purchase history or access patterns [39, 70].\
                For the purpose of simplicity, from this point on, we will call rating any type of user-item response.",

              'An artificial neural network has a more complex structure than that of a \
              perceptron model. The additional complexities may arise in a number of ways : \
              1. The network may contain several intermediary layers between its input \
              and output layers. Such intermediary layers are called hidden layers \
              and the nodes embedded in these layers are called hidden nodes. The \
              resulting structure is known as a multilayer neural network (see Figure \
              5.17). In a feed-forward neural network, the nodes in one layer \
              .Example of a multilayfeere d{onrvaarrdti ficianle uranl etwor(kA NN). \
              are connected only to the nodes in the next layer. The perceptron is a \
              single-layer, feed-forward neural network because it has only one layer \
              of nodes-the output layer that performs complex mathematical operations. \
              fn a recurrent neural network, the links may connect nodes \
              within the same layer or nodes from one layer to the previous layers. \
              2. The network may use types of activation functions other than the sign \
              function. Examples of other activation functions include linear, sigmoid \
              (logistic), and hyperbolic tangent functions, as shown in Figure 5.18. \
              These activation functions allow the hidden and output nodes to produce \
              output values that are nonlinear in their input parameters.',

              'There are different types of neural networks and the differences between them lies in their work principles, the scheme of actions, and the application areas. \
              Convolutional neural networks (CNN) are mostly used for image recognition, and rarely for audio recognition. It is mostly applied to images because there is no need to check all the pixels one by one. \
              CNN checks an image by blocks, starting from the left upper corner and moving further pixel by pixel up to a successful completion. Then the result of every verification is passed through a convolutional layer, \
              where data elements have connections while others don’t. Based on this data, the system can produce the result of the verifications and can conclude what is in the picture',

              'Generally speaking, the reason people could be interested in using a recommender system is that they have so many items to choose from \
              in a limited period of time—that they cannot evaluate all the possible options. A recommender should be able to select and \
              filter all this information to the user. Nowadays, the most successful recommender systems have been built for entertainment content domains, \
              such as: movies, music, or books.']

from sklearn.metrics.pairwise import cosine_similarity

# Initialize an instance of tf-idf Vectorizer
tfidf_vectorizer = TfidfVectorizer()

# Generate the tf-idf vectors for the corpus
tfidf_matrix = tfidf_vectorizer.fit_transform(test_corpus)

# compute and print the cosine similarity matrix
cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)
print(cosine_sim)